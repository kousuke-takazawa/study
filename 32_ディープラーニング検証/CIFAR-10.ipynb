{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cifar10 のデータセットをロード\n",
    "# https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 59  62  63]\n",
      "   [ 43  46  45]\n",
      "   [ 50  48  43]\n",
      "   ..., \n",
      "   [158 132 108]\n",
      "   [152 125 102]\n",
      "   [148 124 103]]\n",
      "\n",
      "  [[ 16  20  20]\n",
      "   [  0   0   0]\n",
      "   [ 18   8   0]\n",
      "   ..., \n",
      "   [123  88  55]\n",
      "   [119  83  50]\n",
      "   [122  87  57]]\n",
      "\n",
      "  [[ 25  24  21]\n",
      "   [ 16   7   0]\n",
      "   [ 49  27   8]\n",
      "   ..., \n",
      "   [118  84  50]\n",
      "   [120  84  50]\n",
      "   [109  73  42]]\n",
      "\n",
      "  ..., \n",
      "  [[208 170  96]\n",
      "   [201 153  34]\n",
      "   [198 161  26]\n",
      "   ..., \n",
      "   [160 133  70]\n",
      "   [ 56  31   7]\n",
      "   [ 53  34  20]]\n",
      "\n",
      "  [[180 139  96]\n",
      "   [173 123  42]\n",
      "   [186 144  30]\n",
      "   ..., \n",
      "   [184 148  94]\n",
      "   [ 97  62  34]\n",
      "   [ 83  53  34]]\n",
      "\n",
      "  [[177 144 116]\n",
      "   [168 129  94]\n",
      "   [179 142  87]\n",
      "   ..., \n",
      "   [216 184 140]\n",
      "   [151 118  84]\n",
      "   [123  92  72]]]\n",
      "\n",
      "\n",
      " [[[154 177 187]\n",
      "   [126 137 136]\n",
      "   [105 104  95]\n",
      "   ..., \n",
      "   [ 91  95  71]\n",
      "   [ 87  90  71]\n",
      "   [ 79  81  70]]\n",
      "\n",
      "  [[140 160 169]\n",
      "   [145 153 154]\n",
      "   [125 125 118]\n",
      "   ..., \n",
      "   [ 96  99  78]\n",
      "   [ 77  80  62]\n",
      "   [ 71  73  61]]\n",
      "\n",
      "  [[140 155 164]\n",
      "   [139 146 149]\n",
      "   [115 115 112]\n",
      "   ..., \n",
      "   [ 79  82  64]\n",
      "   [ 68  70  55]\n",
      "   [ 67  69  55]]\n",
      "\n",
      "  ..., \n",
      "  [[175 167 166]\n",
      "   [156 154 160]\n",
      "   [154 160 170]\n",
      "   ..., \n",
      "   [ 42  34  36]\n",
      "   [ 61  53  57]\n",
      "   [ 93  83  91]]\n",
      "\n",
      "  [[165 154 128]\n",
      "   [156 152 130]\n",
      "   [159 161 142]\n",
      "   ..., \n",
      "   [103  93  96]\n",
      "   [123 114 120]\n",
      "   [131 121 131]]\n",
      "\n",
      "  [[163 148 120]\n",
      "   [158 148 122]\n",
      "   [163 156 133]\n",
      "   ..., \n",
      "   [143 133 139]\n",
      "   [143 134 142]\n",
      "   [143 133 144]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   ..., \n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   [253 253 253]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ..., \n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   ..., \n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   [254 254 254]]\n",
      "\n",
      "  ..., \n",
      "  [[113 120 112]\n",
      "   [111 118 111]\n",
      "   [105 112 106]\n",
      "   ..., \n",
      "   [ 72  81  80]\n",
      "   [ 72  80  79]\n",
      "   [ 72  80  79]]\n",
      "\n",
      "  [[111 118 110]\n",
      "   [104 111 104]\n",
      "   [ 99 106  98]\n",
      "   ..., \n",
      "   [ 68  75  73]\n",
      "   [ 70  76  75]\n",
      "   [ 78  84  82]]\n",
      "\n",
      "  [[106 113 105]\n",
      "   [ 99 106  98]\n",
      "   [ 95 102  94]\n",
      "   ..., \n",
      "   [ 78  85  83]\n",
      "   [ 79  85  83]\n",
      "   [ 80  86  84]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 35 178 235]\n",
      "   [ 40 176 239]\n",
      "   [ 42 176 241]\n",
      "   ..., \n",
      "   [ 99 177 219]\n",
      "   [ 79 147 197]\n",
      "   [ 89 148 189]]\n",
      "\n",
      "  [[ 57 182 234]\n",
      "   [ 44 184 250]\n",
      "   [ 50 183 240]\n",
      "   ..., \n",
      "   [156 182 200]\n",
      "   [141 177 206]\n",
      "   [116 149 175]]\n",
      "\n",
      "  [[ 98 197 237]\n",
      "   [ 64 189 252]\n",
      "   [ 69 192 245]\n",
      "   ..., \n",
      "   [188 195 206]\n",
      "   [119 135 147]\n",
      "   [ 61  79  90]]\n",
      "\n",
      "  ..., \n",
      "  [[ 73  79  77]\n",
      "   [ 53  63  68]\n",
      "   [ 54  68  80]\n",
      "   ..., \n",
      "   [ 17  40  64]\n",
      "   [ 21  36  51]\n",
      "   [ 33  48  49]]\n",
      "\n",
      "  [[ 61  68  75]\n",
      "   [ 55  70  86]\n",
      "   [ 57  79 103]\n",
      "   ..., \n",
      "   [ 24  48  72]\n",
      "   [ 17  35  53]\n",
      "   [  7  23  32]]\n",
      "\n",
      "  [[ 44  56  73]\n",
      "   [ 46  66  88]\n",
      "   [ 49  77 105]\n",
      "   ..., \n",
      "   [ 27  52  77]\n",
      "   [ 21  43  66]\n",
      "   [ 12  31  50]]]\n",
      "\n",
      "\n",
      " [[[189 211 240]\n",
      "   [186 208 236]\n",
      "   [185 207 235]\n",
      "   ..., \n",
      "   [175 195 224]\n",
      "   [172 194 222]\n",
      "   [169 194 220]]\n",
      "\n",
      "  [[194 210 239]\n",
      "   [191 207 236]\n",
      "   [190 206 235]\n",
      "   ..., \n",
      "   [173 192 220]\n",
      "   [171 191 218]\n",
      "   [167 190 216]]\n",
      "\n",
      "  [[208 219 244]\n",
      "   [205 216 240]\n",
      "   [204 215 239]\n",
      "   ..., \n",
      "   [175 191 217]\n",
      "   [172 190 216]\n",
      "   [169 191 215]]\n",
      "\n",
      "  ..., \n",
      "  [[207 199 181]\n",
      "   [203 195 175]\n",
      "   [203 196 173]\n",
      "   ..., \n",
      "   [135 132 127]\n",
      "   [162 158 150]\n",
      "   [168 163 151]]\n",
      "\n",
      "  [[198 190 170]\n",
      "   [189 181 159]\n",
      "   [180 172 147]\n",
      "   ..., \n",
      "   [178 171 160]\n",
      "   [175 169 156]\n",
      "   [175 169 154]]\n",
      "\n",
      "  [[198 189 173]\n",
      "   [189 181 162]\n",
      "   [178 170 149]\n",
      "   ..., \n",
      "   [195 184 169]\n",
      "   [196 189 171]\n",
      "   [195 190 171]]]\n",
      "\n",
      "\n",
      " [[[229 229 239]\n",
      "   [236 237 247]\n",
      "   [234 236 247]\n",
      "   ..., \n",
      "   [217 219 233]\n",
      "   [221 223 234]\n",
      "   [222 223 233]]\n",
      "\n",
      "  [[222 221 229]\n",
      "   [239 239 249]\n",
      "   [233 234 246]\n",
      "   ..., \n",
      "   [223 223 236]\n",
      "   [227 228 238]\n",
      "   [210 211 220]]\n",
      "\n",
      "  [[213 206 211]\n",
      "   [234 232 239]\n",
      "   [231 233 244]\n",
      "   ..., \n",
      "   [220 220 232]\n",
      "   [220 219 232]\n",
      "   [202 203 215]]\n",
      "\n",
      "  ..., \n",
      "  [[150 143 135]\n",
      "   [140 135 127]\n",
      "   [132 127 120]\n",
      "   ..., \n",
      "   [224 222 218]\n",
      "   [230 228 225]\n",
      "   [241 241 238]]\n",
      "\n",
      "  [[137 132 126]\n",
      "   [130 127 120]\n",
      "   [125 121 115]\n",
      "   ..., \n",
      "   [181 180 178]\n",
      "   [202 201 198]\n",
      "   [212 211 207]]\n",
      "\n",
      "  [[122 119 114]\n",
      "   [118 116 110]\n",
      "   [120 116 111]\n",
      "   ..., \n",
      "   [179 177 173]\n",
      "   [164 164 162]\n",
      "   [163 163 161]]]]\n"
     ]
    }
   ],
   "source": [
    "# 各ピクセルの色はRBGで表現\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# 画像数\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# 縦のピクセル数\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# 横のピクセル数\n",
    "print(len(X_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# RGB\n",
    "print(len(X_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " ..., \n",
      " [9]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# クラスラベル\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intをfloatに変換し、0～1に収まるようにする（扱いやすくする）\n",
    "X_train = X_train.astype('float32')\n",
    "X_test  = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test  /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# カテゴライズする\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test  = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークのモデルを定義\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルをコンパイル\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "45000/45000 [==============================] - 151s - loss: 1.6265 - acc: 0.4010 - val_loss: 1.2158 - val_acc: 0.5674\n",
      "Epoch 2/25\n",
      "45000/45000 [==============================] - 149s - loss: 1.2167 - acc: 0.5654 - val_loss: 0.9952 - val_acc: 0.6524\n",
      "Epoch 3/25\n",
      "45000/45000 [==============================] - 150s - loss: 1.0223 - acc: 0.6408 - val_loss: 0.8599 - val_acc: 0.7022\n",
      "Epoch 4/25\n",
      "45000/45000 [==============================] - 152s - loss: 0.9048 - acc: 0.6822 - val_loss: 0.7931 - val_acc: 0.7244\n",
      "Epoch 5/25\n",
      "45000/45000 [==============================] - 153s - loss: 0.8291 - acc: 0.7075 - val_loss: 0.7457 - val_acc: 0.7410\n",
      "Epoch 6/25\n",
      "45000/45000 [==============================] - 151s - loss: 0.7608 - acc: 0.7304 - val_loss: 0.7103 - val_acc: 0.7580\n",
      "Epoch 7/25\n",
      "45000/45000 [==============================] - 153s - loss: 0.7133 - acc: 0.7500 - val_loss: 0.6775 - val_acc: 0.7658\n",
      "Epoch 8/25\n",
      "45000/45000 [==============================] - 154s - loss: 0.6745 - acc: 0.7622 - val_loss: 0.6498 - val_acc: 0.7772\n",
      "Epoch 9/25\n",
      "45000/45000 [==============================] - 159s - loss: 0.6327 - acc: 0.7759 - val_loss: 0.6376 - val_acc: 0.7838\n",
      "Epoch 10/25\n",
      "45000/45000 [==============================] - 155s - loss: 0.6000 - acc: 0.7886 - val_loss: 0.6305 - val_acc: 0.7884\n",
      "Epoch 11/25\n",
      "45000/45000 [==============================] - 164s - loss: 0.5750 - acc: 0.7979 - val_loss: 0.6137 - val_acc: 0.7902\n",
      "Epoch 12/25\n",
      "45000/45000 [==============================] - 167s - loss: 0.5425 - acc: 0.8092 - val_loss: 0.6150 - val_acc: 0.7932\n",
      "Epoch 13/25\n",
      "45000/45000 [==============================] - 167s - loss: 0.5276 - acc: 0.8123 - val_loss: 0.6043 - val_acc: 0.7988\n",
      "Epoch 14/25\n",
      "45000/45000 [==============================] - 171s - loss: 0.5000 - acc: 0.8222 - val_loss: 0.5883 - val_acc: 0.8052\n",
      "Epoch 15/25\n",
      "45000/45000 [==============================] - 171s - loss: 0.4780 - acc: 0.8305 - val_loss: 0.5904 - val_acc: 0.8056\n",
      "Epoch 16/25\n",
      "45000/45000 [==============================] - 169s - loss: 0.4616 - acc: 0.8360 - val_loss: 0.6114 - val_acc: 0.8024\n",
      "Epoch 17/25\n",
      "45000/45000 [==============================] - 171s - loss: 0.4494 - acc: 0.8404 - val_loss: 0.5888 - val_acc: 0.8090\n",
      "Epoch 18/25\n",
      "45000/45000 [==============================] - 174s - loss: 0.4296 - acc: 0.8458 - val_loss: 0.5975 - val_acc: 0.8130\n",
      "Epoch 19/25\n",
      "45000/45000 [==============================] - 164s - loss: 0.4127 - acc: 0.8503 - val_loss: 0.6146 - val_acc: 0.8064\n",
      "Epoch 20/25\n",
      "45000/45000 [==============================] - 157s - loss: 0.3998 - acc: 0.8568 - val_loss: 0.6084 - val_acc: 0.8074\n",
      "Epoch 21/25\n",
      "45000/45000 [==============================] - 155s - loss: 0.3852 - acc: 0.8639 - val_loss: 0.5906 - val_acc: 0.8100\n",
      "Epoch 22/25\n",
      "45000/45000 [==============================] - 158s - loss: 0.3753 - acc: 0.8660 - val_loss: 0.5927 - val_acc: 0.8162\n",
      "Epoch 23/25\n",
      "45000/45000 [==============================] - 154s - loss: 0.3659 - acc: 0.8682 - val_loss: 0.5909 - val_acc: 0.8140\n",
      "Epoch 24/25\n",
      "45000/45000 [==============================] - 158s - loss: 0.3608 - acc: 0.8714 - val_loss: 0.5973 - val_acc: 0.8146\n",
      "Epoch 25/25\n",
      "45000/45000 [==============================] - 155s - loss: 0.3510 - acc: 0.8753 - val_loss: 0.6111 - val_acc: 0.8120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c2ca99cc0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=25, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.657651351213\n",
      "Test accuracy: 0.7956\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
