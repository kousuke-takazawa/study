{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cifar10 のデータセットをロード\n",
    "# https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 59  62  63]\n",
      "   [ 43  46  45]\n",
      "   [ 50  48  43]\n",
      "   ..., \n",
      "   [158 132 108]\n",
      "   [152 125 102]\n",
      "   [148 124 103]]\n",
      "\n",
      "  [[ 16  20  20]\n",
      "   [  0   0   0]\n",
      "   [ 18   8   0]\n",
      "   ..., \n",
      "   [123  88  55]\n",
      "   [119  83  50]\n",
      "   [122  87  57]]\n",
      "\n",
      "  [[ 25  24  21]\n",
      "   [ 16   7   0]\n",
      "   [ 49  27   8]\n",
      "   ..., \n",
      "   [118  84  50]\n",
      "   [120  84  50]\n",
      "   [109  73  42]]\n",
      "\n",
      "  ..., \n",
      "  [[208 170  96]\n",
      "   [201 153  34]\n",
      "   [198 161  26]\n",
      "   ..., \n",
      "   [160 133  70]\n",
      "   [ 56  31   7]\n",
      "   [ 53  34  20]]\n",
      "\n",
      "  [[180 139  96]\n",
      "   [173 123  42]\n",
      "   [186 144  30]\n",
      "   ..., \n",
      "   [184 148  94]\n",
      "   [ 97  62  34]\n",
      "   [ 83  53  34]]\n",
      "\n",
      "  [[177 144 116]\n",
      "   [168 129  94]\n",
      "   [179 142  87]\n",
      "   ..., \n",
      "   [216 184 140]\n",
      "   [151 118  84]\n",
      "   [123  92  72]]]\n",
      "\n",
      "\n",
      " [[[154 177 187]\n",
      "   [126 137 136]\n",
      "   [105 104  95]\n",
      "   ..., \n",
      "   [ 91  95  71]\n",
      "   [ 87  90  71]\n",
      "   [ 79  81  70]]\n",
      "\n",
      "  [[140 160 169]\n",
      "   [145 153 154]\n",
      "   [125 125 118]\n",
      "   ..., \n",
      "   [ 96  99  78]\n",
      "   [ 77  80  62]\n",
      "   [ 71  73  61]]\n",
      "\n",
      "  [[140 155 164]\n",
      "   [139 146 149]\n",
      "   [115 115 112]\n",
      "   ..., \n",
      "   [ 79  82  64]\n",
      "   [ 68  70  55]\n",
      "   [ 67  69  55]]\n",
      "\n",
      "  ..., \n",
      "  [[175 167 166]\n",
      "   [156 154 160]\n",
      "   [154 160 170]\n",
      "   ..., \n",
      "   [ 42  34  36]\n",
      "   [ 61  53  57]\n",
      "   [ 93  83  91]]\n",
      "\n",
      "  [[165 154 128]\n",
      "   [156 152 130]\n",
      "   [159 161 142]\n",
      "   ..., \n",
      "   [103  93  96]\n",
      "   [123 114 120]\n",
      "   [131 121 131]]\n",
      "\n",
      "  [[163 148 120]\n",
      "   [158 148 122]\n",
      "   [163 156 133]\n",
      "   ..., \n",
      "   [143 133 139]\n",
      "   [143 134 142]\n",
      "   [143 133 144]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   ..., \n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   [253 253 253]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ..., \n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   ..., \n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   [254 254 254]]\n",
      "\n",
      "  ..., \n",
      "  [[113 120 112]\n",
      "   [111 118 111]\n",
      "   [105 112 106]\n",
      "   ..., \n",
      "   [ 72  81  80]\n",
      "   [ 72  80  79]\n",
      "   [ 72  80  79]]\n",
      "\n",
      "  [[111 118 110]\n",
      "   [104 111 104]\n",
      "   [ 99 106  98]\n",
      "   ..., \n",
      "   [ 68  75  73]\n",
      "   [ 70  76  75]\n",
      "   [ 78  84  82]]\n",
      "\n",
      "  [[106 113 105]\n",
      "   [ 99 106  98]\n",
      "   [ 95 102  94]\n",
      "   ..., \n",
      "   [ 78  85  83]\n",
      "   [ 79  85  83]\n",
      "   [ 80  86  84]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 35 178 235]\n",
      "   [ 40 176 239]\n",
      "   [ 42 176 241]\n",
      "   ..., \n",
      "   [ 99 177 219]\n",
      "   [ 79 147 197]\n",
      "   [ 89 148 189]]\n",
      "\n",
      "  [[ 57 182 234]\n",
      "   [ 44 184 250]\n",
      "   [ 50 183 240]\n",
      "   ..., \n",
      "   [156 182 200]\n",
      "   [141 177 206]\n",
      "   [116 149 175]]\n",
      "\n",
      "  [[ 98 197 237]\n",
      "   [ 64 189 252]\n",
      "   [ 69 192 245]\n",
      "   ..., \n",
      "   [188 195 206]\n",
      "   [119 135 147]\n",
      "   [ 61  79  90]]\n",
      "\n",
      "  ..., \n",
      "  [[ 73  79  77]\n",
      "   [ 53  63  68]\n",
      "   [ 54  68  80]\n",
      "   ..., \n",
      "   [ 17  40  64]\n",
      "   [ 21  36  51]\n",
      "   [ 33  48  49]]\n",
      "\n",
      "  [[ 61  68  75]\n",
      "   [ 55  70  86]\n",
      "   [ 57  79 103]\n",
      "   ..., \n",
      "   [ 24  48  72]\n",
      "   [ 17  35  53]\n",
      "   [  7  23  32]]\n",
      "\n",
      "  [[ 44  56  73]\n",
      "   [ 46  66  88]\n",
      "   [ 49  77 105]\n",
      "   ..., \n",
      "   [ 27  52  77]\n",
      "   [ 21  43  66]\n",
      "   [ 12  31  50]]]\n",
      "\n",
      "\n",
      " [[[189 211 240]\n",
      "   [186 208 236]\n",
      "   [185 207 235]\n",
      "   ..., \n",
      "   [175 195 224]\n",
      "   [172 194 222]\n",
      "   [169 194 220]]\n",
      "\n",
      "  [[194 210 239]\n",
      "   [191 207 236]\n",
      "   [190 206 235]\n",
      "   ..., \n",
      "   [173 192 220]\n",
      "   [171 191 218]\n",
      "   [167 190 216]]\n",
      "\n",
      "  [[208 219 244]\n",
      "   [205 216 240]\n",
      "   [204 215 239]\n",
      "   ..., \n",
      "   [175 191 217]\n",
      "   [172 190 216]\n",
      "   [169 191 215]]\n",
      "\n",
      "  ..., \n",
      "  [[207 199 181]\n",
      "   [203 195 175]\n",
      "   [203 196 173]\n",
      "   ..., \n",
      "   [135 132 127]\n",
      "   [162 158 150]\n",
      "   [168 163 151]]\n",
      "\n",
      "  [[198 190 170]\n",
      "   [189 181 159]\n",
      "   [180 172 147]\n",
      "   ..., \n",
      "   [178 171 160]\n",
      "   [175 169 156]\n",
      "   [175 169 154]]\n",
      "\n",
      "  [[198 189 173]\n",
      "   [189 181 162]\n",
      "   [178 170 149]\n",
      "   ..., \n",
      "   [195 184 169]\n",
      "   [196 189 171]\n",
      "   [195 190 171]]]\n",
      "\n",
      "\n",
      " [[[229 229 239]\n",
      "   [236 237 247]\n",
      "   [234 236 247]\n",
      "   ..., \n",
      "   [217 219 233]\n",
      "   [221 223 234]\n",
      "   [222 223 233]]\n",
      "\n",
      "  [[222 221 229]\n",
      "   [239 239 249]\n",
      "   [233 234 246]\n",
      "   ..., \n",
      "   [223 223 236]\n",
      "   [227 228 238]\n",
      "   [210 211 220]]\n",
      "\n",
      "  [[213 206 211]\n",
      "   [234 232 239]\n",
      "   [231 233 244]\n",
      "   ..., \n",
      "   [220 220 232]\n",
      "   [220 219 232]\n",
      "   [202 203 215]]\n",
      "\n",
      "  ..., \n",
      "  [[150 143 135]\n",
      "   [140 135 127]\n",
      "   [132 127 120]\n",
      "   ..., \n",
      "   [224 222 218]\n",
      "   [230 228 225]\n",
      "   [241 241 238]]\n",
      "\n",
      "  [[137 132 126]\n",
      "   [130 127 120]\n",
      "   [125 121 115]\n",
      "   ..., \n",
      "   [181 180 178]\n",
      "   [202 201 198]\n",
      "   [212 211 207]]\n",
      "\n",
      "  [[122 119 114]\n",
      "   [118 116 110]\n",
      "   [120 116 111]\n",
      "   ..., \n",
      "   [179 177 173]\n",
      "   [164 164 162]\n",
      "   [163 163 161]]]]\n"
     ]
    }
   ],
   "source": [
    "# 各ピクセルの色はRBGで表現\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# 画像数\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# 縦のピクセル数\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# 横のピクセル数\n",
    "print(len(X_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# RGB\n",
    "print(len(X_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " ..., \n",
      " [9]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# クラスラベル\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intをfloatに変換し、0～1に収まるようにする（扱いやすくする）\n",
    "X_train = X_train.astype('float32')\n",
    "X_test  = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test  /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# カテゴライズする\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test  = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ニューラルネットワークのモデルを定義\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルをコンパイル\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "45000/45000 [==============================] - 17s - loss: 1.6318 - acc: 0.4030 - val_loss: 1.2979 - val_acc: 0.5318\n",
      "Epoch 2/25\n",
      "45000/45000 [==============================] - 12s - loss: 1.2326 - acc: 0.5599 - val_loss: 1.0481 - val_acc: 0.6218\n",
      "Epoch 3/25\n",
      "45000/45000 [==============================] - 12s - loss: 1.0530 - acc: 0.6271 - val_loss: 0.8948 - val_acc: 0.6792\n",
      "Epoch 4/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.9397 - acc: 0.6680 - val_loss: 0.8639 - val_acc: 0.6970\n",
      "Epoch 5/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.8607 - acc: 0.6942 - val_loss: 0.7524 - val_acc: 0.7310\n",
      "Epoch 6/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.8035 - acc: 0.7161 - val_loss: 0.7271 - val_acc: 0.7456\n",
      "Epoch 7/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.7514 - acc: 0.7360 - val_loss: 0.6919 - val_acc: 0.7576\n",
      "Epoch 8/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.7092 - acc: 0.7518 - val_loss: 0.6537 - val_acc: 0.7678\n",
      "Epoch 9/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.6745 - acc: 0.7611 - val_loss: 0.6764 - val_acc: 0.7672\n",
      "Epoch 10/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.6439 - acc: 0.7730 - val_loss: 0.6412 - val_acc: 0.7772\n",
      "Epoch 11/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.6214 - acc: 0.7783 - val_loss: 0.6218 - val_acc: 0.7816\n",
      "Epoch 12/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.5886 - acc: 0.7912 - val_loss: 0.6202 - val_acc: 0.7824\n",
      "Epoch 13/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.5652 - acc: 0.7991 - val_loss: 0.6407 - val_acc: 0.7822\n",
      "Epoch 14/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.5486 - acc: 0.8049 - val_loss: 0.6093 - val_acc: 0.7940\n",
      "Epoch 15/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.5223 - acc: 0.8133 - val_loss: 0.6056 - val_acc: 0.7892\n",
      "Epoch 16/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.5044 - acc: 0.8191 - val_loss: 0.6026 - val_acc: 0.7942\n",
      "Epoch 17/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.4866 - acc: 0.8259 - val_loss: 0.5892 - val_acc: 0.7958\n",
      "Epoch 18/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.4813 - acc: 0.8278 - val_loss: 0.6139 - val_acc: 0.7896\n",
      "Epoch 19/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.4608 - acc: 0.8361 - val_loss: 0.5895 - val_acc: 0.7972\n",
      "Epoch 20/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.4497 - acc: 0.8406 - val_loss: 0.6088 - val_acc: 0.7958\n",
      "Epoch 21/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.4352 - acc: 0.8450 - val_loss: 0.6083 - val_acc: 0.7996\n",
      "Epoch 22/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.4203 - acc: 0.8498 - val_loss: 0.5991 - val_acc: 0.8022\n",
      "Epoch 23/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.4175 - acc: 0.8498 - val_loss: 0.6146 - val_acc: 0.7984\n",
      "Epoch 24/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.4082 - acc: 0.8549 - val_loss: 0.6253 - val_acc: 0.8000\n",
      "Epoch 25/25\n",
      "45000/45000 [==============================] - 12s - loss: 0.4008 - acc: 0.8549 - val_loss: 0.6076 - val_acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20208092550>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=25, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.648174358988\n",
      "Test accuracy: 0.7931\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
